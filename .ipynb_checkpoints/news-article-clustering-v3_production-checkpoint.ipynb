{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import csv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "runParams={'tfidf_maxdf':      [0.5],\n",
    "           'input_file':       ['./data/articles_combined_formattedv2.csv'],\n",
    "           'story_threshold':  [0.26],\n",
    "           'process_date':     ['2016-09-01'],\n",
    "           'parts_of_speech':  [['PROPER', 'VERB']],\n",
    "           'lemma_conversion': [False],\n",
    "           'ngram_max':        [3],\n",
    "           'tfidf_binary':     [False],\n",
    "           'tfidf_norm':       ['l2'],\n",
    "           'nlp_library':      ['nltk'],\n",
    "           'max_length':       [50],\n",
    "           'stop_words_file':  ['./data/stopWords.txt'],\n",
    "           'tfidf_mindf':      [2],\n",
    "           'display_graph':    [True],\n",
    "           'article_stats':    [False]}\n",
    "\n",
    "# Use parameter grid even if there is only set of parameters\n",
    "parameterGrid=ParameterGrid(runParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialise required NLP libraries\n",
    "pos_nlp_mapping={}\n",
    "nl=None\n",
    "wordnet_lemmatizer=None\n",
    "nlp=None\n",
    "if 'spaCy' in runParams['nlp_library']:\n",
    "    import spacy\n",
    "    nlp=spacy.load('en')\n",
    "    pos_nlp_mapping['spaCy']={'VERB':['VERB'],'PROPER':['PROPN'],'COMMON':['NOUN']}\n",
    "    \n",
    "if 'nltk' in runParams['nlp_library']:\n",
    "    import nltk as nl\n",
    "    if True in runParams['lemma_conversion']:\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "    else:\n",
    "        wordnet_lemmatizer=None\n",
    "    pos_nlp_mapping['nltk']={'VERB': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],'PROPER':['NNP','NNPS'],'COMMON':['NN','NNS']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputDataAndDisplayStats(filename,processDate,printSummary=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    logging.warning(\"Length of df before reading: \" + str(df.shape[0]))\n",
    "    df = df.drop_duplicates('content')\n",
    "    df = df[~df['content'].isnull()]\n",
    "    df=df[df['content'].str.len()>=200]\n",
    "\n",
    "    logging.warning(\"Length of df after >=200 strlen: \" + str(df.shape[0]))\n",
    "    \n",
    "    \n",
    "    targetString=\"(Want to get this briefing by email?\"\n",
    "    df['NYT summary']=df['content'].map(lambda d: d[:len(targetString)]==targetString)\n",
    "    df=df[df['NYT summary']==False]\n",
    "\n",
    "    # The following removes a warning that appears in many of the Atlantic articles.\n",
    "    # Since it is commonly at the beginning, it brings a lot of noise to the search for similar articles\n",
    "    # And subsequently to the assessment of sentiment\n",
    "    targetString=\"For us to continue writing great stories, we need to display ads.             Please select the extension that is blocking ads.     Please follow the steps below\"\n",
    "    df['content']=df['content'].str.replace(targetString,'')\n",
    "\n",
    "    # This is also for some Atlantic articles for the same reasons as above\n",
    "    targetString=\"This article is part of a feature we also send out via email as The Atlantic Daily, a newsletter with stories, ideas, and images from The Atlantic, written specially for subscribers. To sign up, please enter your email address in the field provided here.\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "\n",
    "    # This is also for some Atlantic articles for the same reasons as above\n",
    "    targetString=\"This article is part of a feature we also send out via email as Politics  Policy Daily, a daily roundup of events and ideas in American politics written specially for newsletter subscribers. To sign up, please enter your email address in the field provided here.\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "\n",
    "    # More Atlantic-specific removals (for daily summaries with multiple stories contained)\n",
    "    df=df[df['content'].str.contains(\"To sign up, please enter your email address in the field\")==False]\n",
    "\n",
    "    # Remove daily CNN summary\n",
    "    targetString=\"CNN Student News\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "    \n",
    "    # Remove \"Yahoo ist Teil von Verizon Media\"\n",
    "    targetString = \"Yahoo ist Teil von  Verizon Media\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "    \n",
    "    logging.warning(\"Length after other content filtering: \" + str(df.shape[0]))\n",
    "    \n",
    "    print(\"\\nArticle counts by publisher:\")\n",
    "    print(df['publication'].value_counts())\n",
    "\n",
    "    print(\"\\nArticle counts by date:\")\n",
    "    print(df['date'].value_counts())\n",
    "\n",
    "#     Restrict to articles on the provided input date.\n",
    "#     This date is considered mandatory for topic clustering but is not required for sentiment\n",
    "#     since sentiment only processes a specified list of articles.\n",
    "#     For topic clustering it is essential to have the date as it is\n",
    "#     enormously significant in article matching.\n",
    "\n",
    "    if processDate!=None:\n",
    "        df=df[df['date']==processDate]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Remove non-ASCII characters\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df['content no nonascii']=df['content'].map(lambda x: removeNonASCIICharacters(x))\n",
    "\n",
    "    print(\"\\nFinal dataset:\\n\\nDate:\",processDate,\"\\n\")\n",
    "    print(df['publication'].value_counts())\n",
    "    \n",
    "    print(\"\\nFinal Dataset Article Count:\")\n",
    "    print(df['date'].value_counts())\n",
    "    df.to_csv(r'C:\\Users\\goldm\\Capstone\\tracking files\\getInputDataAndDisplayStats.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def removeNonASCIICharacters(textString): \n",
    "    return \"\".join(i for i in textString if ord(i)<128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Length of df before reading: 795\n",
      "WARNING:root:Length of df after >=200 strlen: 772\n",
      "WARNING:root:Length after other content filtering: 764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article counts by publisher:\n",
      "Breitbart             104\n",
      "NY Post                61\n",
      "Reuters                59\n",
      "CNN                    58\n",
      "NPR                    54\n",
      "                     ... \n",
      "The Verge               1\n",
      "The Times of India      1\n",
      "@ChinaDailyApp          1\n",
      "PEOPLE.com              1\n",
      "Forbes                  1\n",
      "Name: publication, Length: 62, dtype: int64\n",
      "\n",
      "Article counts by date:\n",
      "2016-09-01    402\n",
      "2016-12-02    362\n",
      "Name: date, dtype: int64\n",
      "\n",
      "Final dataset:\n",
      "\n",
      "Date: 2016-09-01 \n",
      "\n",
      "Breitbart         50\n",
      "Buzzfeed News     35\n",
      "NY Times          28\n",
      "NY Post           27\n",
      "NPR               26\n",
      "                  ..\n",
      "The Verge          1\n",
      "NewsComAu          1\n",
      "@ChinaDailyApp     1\n",
      "PEOPLE.com         1\n",
      "Forbes             1\n",
      "Name: publication, Length: 62, dtype: int64\n",
      "\n",
      "Final Dataset Article Count:\n",
      "2016-09-01    402\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "articleDataFrame=getInputDataAndDisplayStats(runParams['input_file'][0],\n",
    "                                             runParams['process_date'][0],\n",
    "                                             runParams['article_stats'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Length of df before reading: 795\n",
      "WARNING:root:Length of df after >=200 strlen: 772\n",
      "WARNING:root:Length after other content filtering: 764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article counts by publisher:\n",
      "Breitbart             104\n",
      "NY Post                61\n",
      "Reuters                59\n",
      "CNN                    58\n",
      "NPR                    54\n",
      "                     ... \n",
      "The Verge               1\n",
      "The Times of India      1\n",
      "@ChinaDailyApp          1\n",
      "PEOPLE.com              1\n",
      "Forbes                  1\n",
      "Name: publication, Length: 62, dtype: int64\n",
      "\n",
      "Article counts by date:\n",
      "2016-09-01    402\n",
      "2016-12-02    362\n",
      "Name: date, dtype: int64\n",
      "\n",
      "Final dataset:\n",
      "\n",
      "Date: 2016-09-01 \n",
      "\n",
      "Breitbart         50\n",
      "Buzzfeed News     35\n",
      "NY Times          28\n",
      "NY Post           27\n",
      "NPR               26\n",
      "                  ..\n",
      "The Verge          1\n",
      "NewsComAu          1\n",
      "@ChinaDailyApp     1\n",
      "PEOPLE.com         1\n",
      "Forbes             1\n",
      "Name: publication, Length: 62, dtype: int64\n",
      "\n",
      "Final Dataset Article Count:\n",
      "2016-09-01    402\n",
      "Name: date, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>publication</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>NYT summary</th>\n",
       "      <th>content no nonascii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>21413</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>Another Earth could be circling the star right...</td>\n",
       "      <td>False</td>\n",
       "      <td>Another Earth could be circling the star right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>21448</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>The anodyne welcome letter to incoming freshme...</td>\n",
       "      <td>False</td>\n",
       "      <td>The anodyne welcome letter to incoming freshme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>21454</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>CASETTA, Italy  —   Romano Camassi, a seismolo...</td>\n",
       "      <td>False</td>\n",
       "      <td>CASETTA, Italy     Romano Camassi, a seismolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>21455</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>In the late 1990s, General Motors got an unexp...</td>\n",
       "      <td>False</td>\n",
       "      <td>In the late 1990s, General Motors got an unexp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>21474</td>\n",
       "      <td>NY Times</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>Gene Wilder, who established himself as one of...</td>\n",
       "      <td>False</td>\n",
       "      <td>Gene Wilder, who established himself as one of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>115</td>\n",
       "      <td>217533</td>\n",
       "      <td>The Sun</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>NANCY Pelosi trolled Trump on Thursday by call...</td>\n",
       "      <td>False</td>\n",
       "      <td>NANCY Pelosi trolled Trump on Thursday by call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>116</td>\n",
       "      <td>217534</td>\n",
       "      <td>RT International</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>The Capitol Hill press corps found little symp...</td>\n",
       "      <td>False</td>\n",
       "      <td>The Capitol Hill press corps found little symp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>117</td>\n",
       "      <td>217535</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>US House Speaker  Nancy Pelosi  ’s office has ...</td>\n",
       "      <td>False</td>\n",
       "      <td>US House Speaker  Nancy Pelosi  s office has g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>118</td>\n",
       "      <td>217536</td>\n",
       "      <td>Business Insider</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>-  Adam Kinzinger told NYT Magazine that he su...</td>\n",
       "      <td>False</td>\n",
       "      <td>-  Adam Kinzinger told NYT Magazine that he su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>121</td>\n",
       "      <td>217539</td>\n",
       "      <td>TheHill</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>U.S. Capitol Police (USCP) will begin to remov...</td>\n",
       "      <td>False</td>\n",
       "      <td>U.S. Capitol Police (USCP) will begin to remov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      id       publication        date  \\\n",
       "0             3   21413          NY Times  2016-09-01   \n",
       "1             4   21448          NY Times  2016-09-01   \n",
       "2             5   21454          NY Times  2016-09-01   \n",
       "3             6   21455          NY Times  2016-09-01   \n",
       "4             7   21474          NY Times  2016-09-01   \n",
       "..          ...     ...               ...         ...   \n",
       "397         115  217533           The Sun  2016-09-01   \n",
       "398         116  217534  RT International  2016-09-01   \n",
       "399         117  217535   The Independent  2016-09-01   \n",
       "400         118  217536  Business Insider  2016-09-01   \n",
       "401         121  217539           TheHill  2016-09-01   \n",
       "\n",
       "                                               content  NYT summary  \\\n",
       "0    Another Earth could be circling the star right...        False   \n",
       "1    The anodyne welcome letter to incoming freshme...        False   \n",
       "2    CASETTA, Italy  —   Romano Camassi, a seismolo...        False   \n",
       "3    In the late 1990s, General Motors got an unexp...        False   \n",
       "4    Gene Wilder, who established himself as one of...        False   \n",
       "..                                                 ...          ...   \n",
       "397  NANCY Pelosi trolled Trump on Thursday by call...        False   \n",
       "398  The Capitol Hill press corps found little symp...        False   \n",
       "399  US House Speaker  Nancy Pelosi  ’s office has ...        False   \n",
       "400  -  Adam Kinzinger told NYT Magazine that he su...        False   \n",
       "401  U.S. Capitol Police (USCP) will begin to remov...        False   \n",
       "\n",
       "                                   content no nonascii  \n",
       "0    Another Earth could be circling the star right...  \n",
       "1    The anodyne welcome letter to incoming freshme...  \n",
       "2    CASETTA, Italy     Romano Camassi, a seismolog...  \n",
       "3    In the late 1990s, General Motors got an unexp...  \n",
       "4    Gene Wilder, who established himself as one of...  \n",
       "..                                                 ...  \n",
       "397  NANCY Pelosi trolled Trump on Thursday by call...  \n",
       "398  The Capitol Hill press corps found little symp...  \n",
       "399  US House Speaker  Nancy Pelosi  s office has g...  \n",
       "400  -  Adam Kinzinger told NYT Magazine that he su...  \n",
       "401  U.S. Capitol Police (USCP) will begin to remov...  \n",
       "\n",
       "[402 rows x 7 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getInputDataAndDisplayStats(runParams['input_file'][0],\n",
    "                            runParams['process_date'][0],\n",
    "                            printSummary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyzing if any of the articles were \"kicked out\"\n",
    "def listExcludedArticles(articleDataFrame, storyMap):\n",
    "    excluded_list = []\n",
    "    for story, storyArticles in storyMap.items():\n",
    "        for article in storyArticles:\n",
    "            if article in articleDataFrame['id']:\n",
    "                pass\n",
    "            else:\n",
    "                excluded_list.append(article)\n",
    "    return excluded_list\n",
    "#                 print(str(article) + \" was excluded from the dataset\")\n",
    "# print(articleDataFrame.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords(stopWordsFileName):\n",
    "    stop_words=[]\n",
    "    f=open(stopWordsFileName, 'r')\n",
    "    for l in f.readlines():\n",
    "        stop_words.append(l.replace('\\n', ''))\n",
    "    return stop_words\n",
    "\n",
    "stop_words=loadStopWords(runParams['stop_words_file'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringNLTKProcess(nl,stringToConvert,partsOfSpeech,stop_words,maxWords=None,lemmatizer=None):\n",
    "    sentences=nl.sent_tokenize(stringToConvert)\n",
    "    str=[]\n",
    "    for sentence in sentences:\n",
    "        wordString=[]\n",
    "        for word,pos in nl.pos_tag(nl.word_tokenize(sentence)):\n",
    "            # The following condition avoids any POS which corresponds to punctuation (and takes all others)\n",
    "            if partsOfSpeech==None:\n",
    "                if pos[0]>='A' and pos[0]<='Z':\n",
    "                    wordString.append(word)\n",
    "            elif pos in partsOfSpeech:\n",
    "                wordString.append(word)\n",
    "        for wrd in wordString:\n",
    "            wrdlower=wrd.lower()\n",
    "            if wrdlower not in stop_words and wrdlower!=\"'s\":\n",
    "                if maxWords==None or len(str)<maxWords:\n",
    "                    if lemmatizer==None:\n",
    "                        str.append(wrdlower)\n",
    "                    else:\n",
    "                        str.append(lemmatizer.lemmatize(wrd.lower(), pos='v'))\n",
    "            if maxWords!=None and len(str)==maxWords:\n",
    "                return ' '.join(str)\n",
    "    return ' '.join(str)\n",
    "\n",
    "def removeSpacesAndPunctuation(textString):\n",
    "    return \"\".join(i for i in textString if (ord(i)>=48 and ord(i)<=57) or (ord(i)>=97 and ord(i)<=122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupStoryMapAndReportList(args=None, reportArticleList=None,storyMapFileName=None):\n",
    "    # Story Map is used in fitting if grid search is applied (As ground truth)\n",
    "    # It is also used in graph if no threshold provided (to determine colours, not to determine location)\n",
    "    # Report Article List is used at the end to create a report with, for each\n",
    "    # article in the list, the set of articles within tolerance, and the key words for each\n",
    "    if args==None:\n",
    "        articleList=reportArticleList\n",
    "        fileName=storyMapFileName\n",
    "    else:\n",
    "        articleList=args['article_id_list']\n",
    "        fileName=args['story_map_validation']\n",
    "    \n",
    "    reportArticleList=articleList\n",
    "    if fileName!=None:\n",
    "        storyMap=readStoryMapFromFile(fileName)\n",
    "        if reportArticleList==None:\n",
    "            reportArticleList=[]\n",
    "            for story, articleList in storyMap.items():\n",
    "                reportArticleList.append(articleList[0])\n",
    "    else:\n",
    "        storyMap=None\n",
    "    return storyMap,reportArticleList\n",
    "\n",
    "def readStoryMapFromFile(filename):\n",
    "    return readDictFromCsvFile(filename,'StoryMap')\n",
    "\n",
    "def readGridParameterRangeFromFile(filename):\n",
    "    return readDictFromCsvFile(filename, 'GridParameters')\n",
    "\n",
    "def readDictFromCsvFile(filename,schema):\n",
    "    gridParamDict={} \n",
    "    with open(filename,'r') as f:\n",
    "        for row in f:\n",
    "            row=row[:-1] # Exclude the carriage return\n",
    "            row=row.split(',')\n",
    "            key=row[0]\n",
    "            vals=row[1:]\n",
    "            \n",
    "            if schema=='GridParameters':\n",
    "                if key in ['story_threshold','tfidf_maxdf']:\n",
    "                    finalVals=list(float(n) for n in vals)\n",
    "                elif key in ['ngram_max','tfidf_mindf','max_length']:\n",
    "                    finalVals=list(int(n) for n in vals)\n",
    "                elif key in ['lemma_conversion','tfidf_binary']:\n",
    "                    finalVals = list(str2bool(n) for n in vals)\n",
    "                elif key in ['parts_of_speech']:\n",
    "                    listlist=[]\n",
    "                    for v in vals:\n",
    "                        listlist.append(v_split('+'))\n",
    "                    finalVals = listlist\n",
    "                elif key in ['tfidf_norm','nlp_library']:\n",
    "                    finalVals=vals\n",
    "                else:\n",
    "                    print(key)\n",
    "                    print(\"KEY ERROR\")\n",
    "                    return\n",
    "            elif schema == 'StoryMap':\n",
    "                finalVals = list(int(n) for n in vals if n!='')\n",
    "            else:\n",
    "                print(schema)\n",
    "                print('SCHEMA ERROR')\n",
    "                return\n",
    "            \n",
    "            gridParamDict[key]=finalVals\n",
    "    return gridParamDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "storyMap,reportArticleList=setupStoryMapAndReportList(storyMapFileName='storyMapForValidation_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump meeting : [151832, 110126, 172078, 48306, 57365, 190512, 26536, 71335, 21499, 23872, 142033, 110133, 23888, 71336, 57366, 71339]\n",
      "Brazil impeachment : [120639, 80103, 25225, 21502, 57362, 120636, 110141]\n",
      "Kaepernick : [40617, 40543, 39520, 80109, 80101, 47403]\n",
      "Clinton Guccifer : [214888, 85803, 47979]\n",
      "Farage : [37252, 37468, 46175]\n",
      "Anthony Weiner : [49480, 110144, 142300, 214934]\n",
      "SpaceX : [38658, 134545, 172095, 214894]\n",
      "Safe space : [21448, 78169, 78171]\n",
      "Lauer debate : [43447, 47078, 138709]\n",
      "Venezuela : [172079, 57375, 190522]\n",
      "Iran deal : [158005, 48823, 57373, 120634]\n",
      "Penn State : [80094, 157527, 214892]\n",
      "David Brown : [172085, 80096, 141886]\n",
      "haiti AND president : [217418, 217419, 217420, 217421, 217422, 217423, 217424, 217425, 217426, 217427, 217428, 217429, 217430, 217431, 217432, 217433, 217434, 217435, 217436, 217437, 217438, 217439, 217440, 217441]\n",
      "inflation AND economy AND fed : [217490, 217491, 217492, 217493, 217494, 217495, 217496, 217497, 217498, 217499, 217500, 217501, 217502, 217504, 217505, 217506, 217507, 217508, 217509, 217510, 217511, 217513, 217514]\n",
      "afghanistan AND war AND end : [217442, 217443, 217444, 217445, 217446, 217447, 217448, 217449, 217450, 217451, 217452, 217453, 217454, 217455, 217456, 217457, 217458, 217459, 217460, 217461, 217462, 217463, 217464, 217465]\n",
      "capitol AND riot AND trump : [217517, 217519, 217520, 217521, 217522, 217523, 217524, 217526, 217527, 217528, 217529, 217530, 217531, 217532, 217533, 217534, 217535, 217536, 217539]\n",
      "critical AND race AND theory : [217466, 217467, 217468, 217469, 217470, 217471, 217472, 217473, 217474, 217475, 217476, 217477, 217478, 217481, 217482, 217483, 217484, 217485, 217486, 217487, 217488, 217489]\n"
     ]
    }
   ],
   "source": [
    "for story, articleList in storyMap.items():\n",
    "    print(story,\":\",articleList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump meeting : [151832, 110126, 172078, 48306, 57365, 190512, 26536, 71335, 21499, 23872, 142033, 110133, 23888, 71336, 57366, 71339]\n",
      "Brazil impeachment : [120639, 80103, 25225, 21502, 57362, 120636, 110141]\n",
      "Kaepernick : [40617, 40543, 39520, 80109, 80101, 47403]\n",
      "Clinton Guccifer : [214888, 85803, 47979]\n",
      "Farage : [37252, 37468, 46175]\n",
      "Anthony Weiner : [49480, 110144, 142300, 214934]\n",
      "SpaceX : [38658, 134545, 172095, 214894]\n",
      "Safe space : [21448, 78169, 78171]\n",
      "Lauer debate : [43447, 47078, 138709]\n",
      "Venezuela : [172079, 57375, 190522]\n",
      "Iran deal : [158005, 48823, 57373, 120634]\n",
      "Penn State : [80094, 157527, 214892]\n",
      "David Brown : [172085, 80096, 141886]\n",
      "haiti AND president : [217418, 217419, 217420, 217421, 217422, 217424, 217425, 217426, 217427, 217428, 217429, 217430, 217431, 217433, 217434, 217435, 217436, 217437, 217438, 217439, 217440, 217441]\n",
      "inflation AND economy AND fed : [217490, 217492, 217493, 217494, 217495, 217496, 217497, 217498, 217500, 217501, 217502, 217504, 217505, 217506, 217507, 217508, 217509, 217510, 217511, 217513, 217514]\n",
      "afghanistan AND war AND end : [217442, 217444, 217446, 217447, 217448, 217450, 217451, 217453, 217454, 217455, 217456, 217457, 217458, 217459, 217460, 217461, 217462, 217464, 217465]\n",
      "capitol AND riot AND trump : [217517, 217519, 217520, 217521, 217522, 217523, 217524, 217526, 217527, 217529, 217530, 217531, 217532, 217533, 217534, 217535, 217536, 217539]\n",
      "critical AND race AND theory : [217466, 217467, 217468, 217469, 217470, 217471, 217472, 217473, 217474, 217475, 217476, 217477, 217478, 217481, 217482, 217483, 217484, 217485, 217486, 217488]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## print out whether any of the labeled articles have been excluded\n",
    "excluded_list = listExcludedArticles(articleDataFrame,storyMap)\n",
    "for story, articleList in storyMap.items():\n",
    "    print(story,\":\",[article for article in articleList if article in list(articleDataFrame['id'])])\n",
    "print(172078 in list(articleDataFrame['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessAndVectorize(articleDataFrame,args,pos_nlp_mapping,nlp,nl,wordnet_lemmatizer,stop_words):\n",
    "    # Map the input parts of speech list to the coding required for the specific NLP library\n",
    "    if args['parts_of_speech'][0]!='ALL':\n",
    "        partsOfSpeech=[]\n",
    "        for pos in args['parts_of_speech']:\n",
    "            partsOfSpeech.append(pos_nlp_mapping[args['nlp_library']][pos])\n",
    "        partsOfSpeech=[item for sublist in partsOfSpeech for item in sublist]\n",
    "    else:\n",
    "        partsOfSpeech=None\n",
    "    \n",
    "    # Processing of text depends on NLP library choice\n",
    "    if args['nlp_library']=='spaCy':\n",
    "        articleDataFrame['input to vectorizer']=articleDataFrame['content no nonascii'].map(lambda x: stringSpaCyProcess(nlp,\n",
    "                                                                                                                         x,\n",
    "                                                                                                                         partsOfSpeech=partsOfSpeech,\n",
    "                                                                                                                         maxWords=args['max_length'],\n",
    "                                                                                                                         stop_words=stop_words,\n",
    "                                                                                                                         lemmatize=args['lemma_conversion']))\n",
    "    elif args['nlp_library']=='nltk':\n",
    "        articleDataFrame['input to vectorizer']=articleDataFrame['content no nonascii'].map(lambda x: stringNLTKProcess(nl,\n",
    "                                                                                                                        x,\n",
    "                                                                                                                        partsOfSpeech=partsOfSpeech,\n",
    "                                                                                                                        stop_words=stop_words,\n",
    "                                                                                                                        maxWords=args['max_length'],\n",
    "                                                                                                                        lemmatizer=wordnet_lemmatizer))\n",
    "    else:\n",
    "        print(\"PROBLEM... NO VALID NLP LIBRARY... MUST BE nltk OR spaCy\")\n",
    "\n",
    "    # To get default values a couple of parameters need to be not passed if not specified on the command line\n",
    "    # Passing as None behaves differently to passing no parameter (which would invoke the default value)\n",
    "    optArgsForVectorizer={}\n",
    "    if args['tfidf_maxdf'] != None:\n",
    "        optArgsForVectorizer['max_df']=args['tfidf_maxdf']\n",
    "    if args['tfidf_mindf'] != None:\n",
    "        optArgsForVectorizer['min_df']=args['tfidf_mindf']\n",
    "    # Create and run the vectorize\n",
    "    vectorizer=TfidfVectorizer(analyzer='word',\n",
    "                               ngram_range=(1,args['ngram_max']),\n",
    "                              lowercase=True,\n",
    "                              binary=args['tfidf_binary'],\n",
    "                              norm=args['tfidf_norm'],\n",
    "                              **optArgsForVectorizer)\n",
    "    tfidfVectors=vectorizer.fit_transform(articleDataFrame['input to vectorizer'])\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    logging.warning('tfidfVector shape: '+ str(tfidfVectors.shape)) \n",
    "    \n",
    "    return tfidfVectors, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,threshold,printErrors=False):\n",
    "    # Work with distances relative to first item in each cluster - even though this is clearly arbitrary since that\n",
    "    # point could be an outlier in the cluster and hence might cause problems.\n",
    "    # But I have to start somewhere - and can refine it later if needed.\n",
    "\n",
    "    nonZeroCoords=initialiseAllNonZeroCoords(tfidfVectors)\n",
    "    score=0\n",
    "    outGood=0\n",
    "    outBad=0\n",
    "    inGood=0\n",
    "    inBad=0\n",
    "     \n",
    "    #### ---- Richard Modification- adding in code to print out a df of articles in the story map and their respective category       \n",
    "    final_mapping_list = []\n",
    "    \n",
    "    for story, storyArticles in storyMap.items():\n",
    "        leadArticleIndex=articleDataFrame[articleDataFrame['id']==storyArticles[0]].index[0]\n",
    "        comparisonArticle = articleDataFrame[articleDataFrame['id']==storyArticles[0]]['id']\n",
    "        # Compute score of all articles in corpus relative to first article in story (.product)\n",
    "        # Then count through list relative to threshold (add one for a good result, subtract one for a bad result)\n",
    "        scores=productRelatednessScores(tfidfVectors,nonZeroCoords,leadArticleIndex)\n",
    "        rankedIndices=np.argsort(scores)\n",
    "        foundRelatedArticles=[]\n",
    "        # THE SORTING HERE IS NOT STRICTLY REQUIRED, BUT I COULD USE IT SO THAT ONCE THE THRESHOLD IS PASSED\n",
    "        # IN THE LOOP, THEN I INFER THE REMAINING RESULTS\n",
    "        for article in reversed(rankedIndices):\n",
    "            thisArticleIndex=articleDataFrame['id'][article]\n",
    "            if thisArticleIndex in storyArticles:\n",
    "                if scores[article]>=threshold: # article IS supposed to be in range\n",
    "                    score+=1\n",
    "                    inGood+=1\n",
    "                    #appending the article and its mapping according to the predictions of our model\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, story, 'TP', scores[article]])\n",
    "                else:\n",
    "                    score-=1\n",
    "                    inBad+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, 'No Mapping', story, 'FN', scores[article]])\n",
    "                    if printErrors:\n",
    "                        print(\"ERROR:\",thisArticleIndex,\"should be in\",story)\n",
    "            else: # article not supposed to be in range\n",
    "                if scores[article]<=threshold:\n",
    "                    score+=1\n",
    "                    outGood+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, 'No Mapping', 'No Mapping', 'TN', scores[article]])\n",
    "                else:\n",
    "                    score-=1\n",
    "                    outBad+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, story, 'No Mapping', 'No Mapping', 'FP', scores[article]])\n",
    "                    if printErrors:\n",
    "                        print(\"ERROR:\",thisArticleIndex,\"should NOT be in\",story)\n",
    "    \n",
    "    #### ---- Richard Modification- adding in code to print out a df of articles in the story map and their respective categor\n",
    "    final_mapping_df = pd.DataFrame(final_mapping_list, columns = ['root_article', 'article_compared', 'predicted_mapping', 'true_mapping\"','FP/FN/TP/TN', \"score\"])\n",
    "    final_mapping_df = final_mapping_df[final_mapping_df.score != 0]\n",
    "    final_mapping_df.to_csv(\"PredictedMappingsv4-storythreshold={}.csv\".format(threshold))\n",
    "    \n",
    "    scoreDict={'score':score,'inGood':inGood,'inBad':inBad,'outGood':outGood,'outBad':outBad}\n",
    "    return scoreDict\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def initialiseAllNonZeroCoords(tfidfVectors):\n",
    "# This function just exists since it seems to be expensive and I'd rather not call it multiple times\n",
    "# Hence it is intended to be called outside of loops in order to simplify the row specific processing\n",
    "    values=[]\n",
    "    nzc=zip(*tfidfVectors.nonzero())\n",
    "\n",
    "    # In Python 3 the zip can only be iterated through one time before it is automatically released\n",
    "    # So need to copy the results otherwise the main loop below will no longer work\n",
    "    pointList=[]\n",
    "    for i,j in nzc:\n",
    "        pointList.append([i,j])\t\t\n",
    "\n",
    "    for row in range(tfidfVectors.shape[0]):\n",
    "        rowList=[]\n",
    "        for i,j in pointList:\n",
    "            if row==i:\n",
    "                rowList.append(j)\n",
    "        values.append(rowList)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productRelatednessScores(tfidfVectors,nonZeroCoords,refRow):\n",
    "    # instantiates a matrix of zeros with tfidVectors.shape[0] rows corresponding to the number of rows in the tfidVectors array\n",
    "    scores = [0]*tfidfVectors.shape[0]\n",
    "    for toRow in range(tfidfVectors.shape[0]):\n",
    "        scores[toRow] = sum([(tfidfVectors[toRow,w]*tfidfVectors[refRow,w]) for w in nonZeroCoords[refRow] if w in nonZeroCoords[toRow]])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goldm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk; nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tfidfVector shape: (402, 4182)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 7064, 'inGood': 80, 'inBad': 82, 'outGood': 7070, 'outBad': 4}\n"
     ]
    }
   ],
   "source": [
    "# Loop across all parameter combinations in grid to determine best set\n",
    "# If not doing grid search, will just pass through the loop once\n",
    "bestParamScoreDict={'score':-1000000}\n",
    "bestParams=parameterGrid[0]\n",
    "for i,currentParams in enumerate(parameterGrid):\n",
    "    if len(parameterGrid)>1:\n",
    "        print(\"Combination:\",i+1,\"of\",len(parameterGrid))\n",
    "        print(currentParams)\n",
    "        \n",
    "        # Determine tf-idf vectors\n",
    "        # terms is just used later on if analysis of final results is requested\n",
    "    tfidfVectors,terms=preprocessAndVectorize(articleDataFrame,\n",
    "                                              currentParams,\n",
    "                                              pos_nlp_mapping,\n",
    "                                              nlp,\n",
    "                                              nl,\n",
    "                                              wordnet_lemmatizer,\n",
    "                                              stop_words)\n",
    "\n",
    "    # Compute scores if threshold provided (meaning as part of grid search)\n",
    "    if 'story_threshold' in currentParams and currentParams['story_threshold']!=None:\n",
    "        scoreDict = scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,currentParams['story_threshold'])\n",
    "        print(scoreDict)\n",
    "\n",
    "        # Update best so far\n",
    "        if scoreDict['score']>=bestParamScoreDict['score']:\n",
    "            if len(parameterGrid)>1:\n",
    "                print(i+1,\"is the best so far!\")\n",
    "            bestParams=currentParams\n",
    "            bestParamScoreDict=scoreDict\n",
    "    # End grid/parameter loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS:\n",
      "{'article_stats': False, 'display_graph': True, 'input_file': './data/articles_combined_formattedv1.csv', 'lemma_conversion': False, 'max_length': 50, 'ngram_max': 3, 'nlp_library': 'nltk', 'parts_of_speech': ['PROPER', 'VERB'], 'process_date': '2016-09-01', 'stop_words_file': './data/stopWords.txt', 'story_threshold': 0.2, 'tfidf_binary': False, 'tfidf_maxdf': 0.5, 'tfidf_mindf': 2, 'tfidf_norm': 'l2'}\n",
      "{'score': 7356, 'inGood': 86, 'inBad': 95, 'outGood': 7381, 'outBad': 16}\n",
      "ERROR: 214876 should NOT be in Trump meeting\n",
      "ERROR: 80098 should NOT be in Trump meeting\n",
      "ERROR: 78170 should NOT be in Trump meeting\n",
      "ERROR: 44928 should NOT be in Trump meeting\n",
      "ERROR: 71339 should be in Trump meeting\n",
      "ERROR: 85801 should NOT be in Clinton Guccifer\n",
      "ERROR: 44642 should NOT be in Safe space\n",
      "ERROR: 85799 should NOT be in Lauer debate\n",
      "ERROR: 39232 should NOT be in David Brown\n",
      "ERROR: 71350 should NOT be in David Brown\n",
      "ERROR: 217425 should be in haiti AND president\n",
      "ERROR: 217437 should be in haiti AND president\n",
      "ERROR: 217429 should be in haiti AND president\n",
      "ERROR: 217426 should be in haiti AND president\n",
      "ERROR: 217439 should be in haiti AND president\n",
      "ERROR: 217433 should be in haiti AND president\n",
      "ERROR: 217422 should be in haiti AND president\n",
      "ERROR: 217419 should be in haiti AND president\n",
      "ERROR: 217421 should be in haiti AND president\n",
      "ERROR: 217432 should be in haiti AND president\n",
      "ERROR: 217438 should be in haiti AND president\n",
      "ERROR: 217428 should be in haiti AND president\n",
      "ERROR: 217420 should be in haiti AND president\n",
      "ERROR: 217435 should be in haiti AND president\n",
      "ERROR: 217431 should be in haiti AND president\n",
      "ERROR: 217427 should be in haiti AND president\n",
      "ERROR: 217418 should be in haiti AND president\n",
      "ERROR: 217424 should be in haiti AND president\n",
      "ERROR: 217430 should be in haiti AND president\n",
      "ERROR: 217500 should be in inflation AND economy AND fed\n",
      "ERROR: 217497 should be in inflation AND economy AND fed\n",
      "ERROR: 217504 should be in inflation AND economy AND fed\n",
      "ERROR: 217495 should be in inflation AND economy AND fed\n",
      "ERROR: 217501 should be in inflation AND economy AND fed\n",
      "ERROR: 217503 should be in inflation AND economy AND fed\n",
      "ERROR: 217496 should be in inflation AND economy AND fed\n",
      "ERROR: 217509 should be in inflation AND economy AND fed\n",
      "ERROR: 217506 should be in inflation AND economy AND fed\n",
      "ERROR: 217513 should be in inflation AND economy AND fed\n",
      "ERROR: 217512 should be in inflation AND economy AND fed\n",
      "ERROR: 217505 should be in inflation AND economy AND fed\n",
      "ERROR: 217499 should be in inflation AND economy AND fed\n",
      "ERROR: 217494 should be in inflation AND economy AND fed\n",
      "ERROR: 217502 should be in inflation AND economy AND fed\n",
      "ERROR: 217508 should be in inflation AND economy AND fed\n",
      "ERROR: 217511 should be in inflation AND economy AND fed\n",
      "ERROR: 217445 should be in afghanistan AND war AND end\n",
      "ERROR: 217456 should be in afghanistan AND war AND end\n",
      "ERROR: 217452 should be in afghanistan AND war AND end\n",
      "ERROR: 217453 should be in afghanistan AND war AND end\n",
      "ERROR: 217464 should be in afghanistan AND war AND end\n",
      "ERROR: 217459 should be in afghanistan AND war AND end\n",
      "ERROR: 217455 should be in afghanistan AND war AND end\n",
      "ERROR: 217447 should be in afghanistan AND war AND end\n",
      "ERROR: 217448 should be in afghanistan AND war AND end\n",
      "ERROR: 217450 should be in afghanistan AND war AND end\n",
      "ERROR: 217458 should be in afghanistan AND war AND end\n",
      "ERROR: 217460 should be in afghanistan AND war AND end\n",
      "ERROR: 217457 should be in afghanistan AND war AND end\n",
      "ERROR: 217443 should be in afghanistan AND war AND end\n",
      "ERROR: 217444 should be in afghanistan AND war AND end\n",
      "ERROR: 217446 should be in afghanistan AND war AND end\n",
      "ERROR: 217454 should be in afghanistan AND war AND end\n",
      "ERROR: 217461 should be in afghanistan AND war AND end\n",
      "ERROR: 217462 should be in afghanistan AND war AND end\n",
      "ERROR: 217451 should be in afghanistan AND war AND end\n",
      "ERROR: 217449 should be in afghanistan AND war AND end\n",
      "ERROR: 217463 should be in afghanistan AND war AND end\n",
      "ERROR: 217502 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217511 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217479 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217478 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217508 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217488 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217485 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217538 should be in capitol AND riot AND trump\n",
      "ERROR: 217516 should be in capitol AND riot AND trump\n",
      "ERROR: 217518 should be in capitol AND riot AND trump\n",
      "ERROR: 217519 should be in capitol AND riot AND trump\n",
      "ERROR: 217520 should be in capitol AND riot AND trump\n",
      "ERROR: 217521 should be in capitol AND riot AND trump\n",
      "ERROR: 217522 should be in capitol AND riot AND trump\n",
      "ERROR: 217523 should be in capitol AND riot AND trump\n",
      "ERROR: 217525 should be in capitol AND riot AND trump\n",
      "ERROR: 217526 should be in capitol AND riot AND trump\n",
      "ERROR: 217528 should be in capitol AND riot AND trump\n",
      "ERROR: 217529 should be in capitol AND riot AND trump\n",
      "ERROR: 217530 should be in capitol AND riot AND trump\n",
      "ERROR: 217531 should be in capitol AND riot AND trump\n",
      "ERROR: 217532 should be in capitol AND riot AND trump\n",
      "ERROR: 217533 should be in capitol AND riot AND trump\n",
      "ERROR: 217534 should be in capitol AND riot AND trump\n",
      "ERROR: 217535 should be in capitol AND riot AND trump\n",
      "ERROR: 217475 should be in critical AND race AND theory\n",
      "ERROR: 217477 should be in critical AND race AND theory\n",
      "ERROR: 217470 should be in critical AND race AND theory\n",
      "ERROR: 217473 should be in critical AND race AND theory\n",
      "ERROR: 217468 should be in critical AND race AND theory\n",
      "ERROR: 217467 should be in critical AND race AND theory\n",
      "ERROR: 217480 should be in critical AND race AND theory\n",
      "ERROR: 217487 should be in critical AND race AND theory\n",
      "ERROR: 217481 should be in critical AND race AND theory\n",
      "ERROR: 217471 should be in critical AND race AND theory\n",
      "ERROR: 217484 should be in critical AND race AND theory\n",
      "ERROR: 217486 should be in critical AND race AND theory\n",
      "ERROR: 217474 should be in critical AND race AND theory\n",
      "ERROR: 217476 should be in critical AND race AND theory\n",
      "ERROR: 217478 should be in critical AND race AND theory\n",
      "ERROR: 217479 should be in critical AND race AND theory\n",
      "ERROR: 217485 should be in critical AND race AND theory\n",
      "ERROR: 217488 should be in critical AND race AND theory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tfidfVector shape: (421, 4727)\n"
     ]
    }
   ],
   "source": [
    "# Set threshold to input value from best (and possibly only) run for use in results analysis\n",
    "# Unless not specified at all\n",
    "if 'story_threshold' in bestParams and bestParams['story_threshold']!=None:\n",
    "    threshold=bestParams['story_threshold']\n",
    "else:\n",
    "    threshold=None\n",
    "\n",
    "\n",
    "# If there was a real parameter grid, then output/refresh results\n",
    "if len(parameterGrid)>=1:\n",
    "    print(\"BEST PARAMETERS:\")\n",
    "    print(bestParams)\n",
    "    print(bestParamScoreDict)\n",
    "    scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,threshold,printErrors=True)\n",
    "    # Recreate vector for best results in loop\n",
    "    # terms is just used later on if analysis of final results is requested\n",
    "    tfidfVectors,terms=preprocessAndVectorize(articleDataFrame,\n",
    "                                            bestParams,\n",
    "                                            pos_nlp_mapping,\n",
    "                                            nlp,\n",
    "                                            nl,\n",
    "                                            wordnet_lemmatizer,\n",
    "                                            stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets generate a confusion matrix to evaluate our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels= pd.read_csv(r\"C:\\Users\\goldm\\Capstone\\full_article_classifications_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48306</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57365</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     true-label\n",
       "0  151832  Trump meeting\n",
       "1  110126  Trump meeting\n",
       "2  172078  Trump meeting\n",
       "3   48306  Trump meeting\n",
       "4   57365  Trump meeting"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.columns = ['id','true-label']\n",
    "true_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mappings_df = pd.read_csv(r\"C:\\Users\\goldm\\Capstone\\PredictedMappingsv4-storythreshold=0.26.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>root_article</th>\n",
       "      <th>article_compared</th>\n",
       "      <th>predicted_mapping</th>\n",
       "      <th>true_mapping\"</th>\n",
       "      <th>FP/FN/TP/TN</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.0000000000000004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>48306</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.42140893269377533</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.40039220520430624</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.37401423503171455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>26536</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.3469127131230455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           root_article  article_compared  \\\n",
       "0           0  227    151832\\nName: id, dtype: int64            151832   \n",
       "1           1  227    151832\\nName: id, dtype: int64             48306   \n",
       "2           2  227    151832\\nName: id, dtype: int64            172078   \n",
       "3           3  227    151832\\nName: id, dtype: int64            110126   \n",
       "4           4  227    151832\\nName: id, dtype: int64             26536   \n",
       "\n",
       "  predicted_mapping true_mapping\"          FP/FN/TP/TN  score  \n",
       "0     Trump meeting            TP   1.0000000000000004    NaN  \n",
       "1     Trump meeting            TP  0.42140893269377533    NaN  \n",
       "2     Trump meeting            TP  0.40039220520430624    NaN  \n",
       "3     Trump meeting            TP  0.37401423503171455    NaN  \n",
       "4     Trump meeting            TP   0.3469127131230455    NaN  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mappings_df = predicted_mappings_df[['article_compared','cateogry ID']]\n",
    "predicted_mappings_df.columns = ['id','predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48306</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57365</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>217509</td>\n",
       "      <td>inflation AND economy AND fed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>217510</td>\n",
       "      <td>inflation AND economy AND fed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>217511</td>\n",
       "      <td>inflation AND economy AND fed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>217513</td>\n",
       "      <td>inflation AND economy AND fed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>217514</td>\n",
       "      <td>inflation AND economy AND fed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                     true-label\n",
       "0    151832                  Trump meeting\n",
       "1    110126                  Trump meeting\n",
       "2    172078                  Trump meeting\n",
       "3     48306                  Trump meeting\n",
       "4     57365                  Trump meeting\n",
       "..      ...                            ...\n",
       "169  217509  inflation AND economy AND fed\n",
       "170  217510  inflation AND economy AND fed\n",
       "171  217511  inflation AND economy AND fed\n",
       "172  217513  inflation AND economy AND fed\n",
       "173  217514  inflation AND economy AND fed\n",
       "\n",
       "[174 rows x 2 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df.drop_duplicates()\n",
    "true_labels.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_mappings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>151832</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     true-label\n",
       "0     151832  Trump meeting\n",
       "350   151832     No Mapping\n",
       "481   151832     No Mapping\n",
       "663   151832     No Mapping\n",
       "1291  151832     No Mapping\n",
       "1509  151832     No Mapping\n",
       "1877  151832     No Mapping\n",
       "2050  151832     No Mapping\n",
       "2057  151832     No Mapping\n",
       "2328  151832     No Mapping\n",
       "2556  151832     No Mapping\n",
       "2598  151832     No Mapping\n",
       "2799  151832     No Mapping\n",
       "3487  151832     No Mapping\n",
       "3748  151832     No Mapping\n",
       "3865  151832     No Mapping"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df.head()\n",
    "predicted_mappings_df[predicted_mappings_df['id'] == 151832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true_label_x</th>\n",
       "      <th>true_label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   true_label_x   true_label_y\n",
       "0  151832  Trump meeting  Trump meeting\n",
       "1  151832  Trump meeting     No Mapping\n",
       "2  110126  Trump meeting  Trump meeting\n",
       "3  110126  Trump meeting     No Mapping\n",
       "4  172078  Trump meeting  Trump meeting"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join the predictions to the true labels\n",
    "combined_matrix_df = combined_true_labels_df.merge(predicted_mappings_df, how='inner', on='id')\n",
    "combined_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true_label_x</th>\n",
       "      <th>true_label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21499</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21499</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>21502</td>\n",
       "      <td>Brazil impeachment</td>\n",
       "      <td>Brazil impeachment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21502</td>\n",
       "      <td>Brazil impeachment</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23872</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>217536</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>217537</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>217537</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>217538</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>217538</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                true_label_x                true_label_y\n",
       "17    21499               Trump meeting                  No Mapping\n",
       "16    21499               Trump meeting               Trump meeting\n",
       "39    21502          Brazil impeachment          Brazil impeachment\n",
       "38    21502          Brazil impeachment                  No Mapping\n",
       "18    23872               Trump meeting               Trump meeting\n",
       "..      ...                         ...                         ...\n",
       "361  217536  capitol AND riot AND trump  capitol AND riot AND trump\n",
       "362  217537  capitol AND riot AND trump                  No Mapping\n",
       "363  217537  capitol AND riot AND trump  capitol AND riot AND trump\n",
       "364  217538  capitol AND riot AND trump                  No Mapping\n",
       "365  217538  capitol AND riot AND trump                  No Mapping\n",
       "\n",
       "[366 rows x 3 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_df.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true_label_x</th>\n",
       "      <th>true_label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   true_label_x   true_label_y\n",
       "0  151832  Trump meeting  Trump meeting\n",
       "1  151832  Trump meeting     No Mapping"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_df[combined_matrix_df['id'] == 151832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     true_label\n",
       "0  151832  Trump meeting"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_true_labels_df[combined_true_labels_df['id'] == 151832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true_label_x</th>\n",
       "      <th>true_label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>217537</td>\n",
       "      <td>capitol AND riot AND trump</td>\n",
       "      <td>No Mapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                true_label_x true_label_y\n",
       "362  217537  capitol AND riot AND trump   No Mapping"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_matrix_df = combined_matrix_df.drop_duplicates(subset=['id'])\n",
    "combined_matrix_df[combined_matrix_df['id'] == 217537]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
