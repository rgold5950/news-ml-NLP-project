{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import csv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "runParams={'tfidf_maxdf':      [0.5],\n",
    "           'input_file':       ['./data/articles_combined_formattedv2.csv'],\n",
    "           'story_threshold':  [0.26],\n",
    "           'process_date':     ['2016-09-01'],\n",
    "           'parts_of_speech':  [['PROPER', 'VERB']],\n",
    "           'lemma_conversion': [False],\n",
    "           'ngram_max':        [3],\n",
    "           'tfidf_binary':     [False],\n",
    "           'tfidf_norm':       ['l2'],\n",
    "           'nlp_library':      ['nltk'],\n",
    "           'max_length':       [50],\n",
    "           'stop_words_file':  ['./data/stopWords.txt'],\n",
    "           'tfidf_mindf':      [2],\n",
    "           'display_graph':    [True],\n",
    "           'article_stats':    [False]}\n",
    "\n",
    "# Use parameter grid even if there is only set of parameters\n",
    "parameterGrid=ParameterGrid(runParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and initialise required NLP libraries\n",
    "pos_nlp_mapping={}\n",
    "nl=None\n",
    "wordnet_lemmatizer=None\n",
    "nlp=None\n",
    "if 'spaCy' in runParams['nlp_library']:\n",
    "    import spacy\n",
    "    nlp=spacy.load('en')\n",
    "    pos_nlp_mapping['spaCy']={'VERB':['VERB'],'PROPER':['PROPN'],'COMMON':['NOUN']}\n",
    "    \n",
    "if 'nltk' in runParams['nlp_library']:\n",
    "    import nltk as nl\n",
    "    if True in runParams['lemma_conversion']:\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "    else:\n",
    "        wordnet_lemmatizer=None\n",
    "    pos_nlp_mapping['nltk']={'VERB': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],'PROPER':['NNP','NNPS'],'COMMON':['NN','NNS']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputDataAndDisplayStats(filename,processDate,printSummary=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    logging.warning(\"Length of df before reading: \" + str(df.shape[0]))\n",
    "    df = df.drop_duplicates('content')\n",
    "    df = df[~df['content'].isnull()]\n",
    "    df=df[df['content'].str.len()>=200]\n",
    "\n",
    "    logging.warning(\"Length of df after >=200 strlen: \" + str(df.shape[0]))\n",
    "    \n",
    "    \n",
    "    targetString=\"(Want to get this briefing by email?\"\n",
    "    df['NYT summary']=df['content'].map(lambda d: d[:len(targetString)]==targetString)\n",
    "    df=df[df['NYT summary']==False]\n",
    "\n",
    "    # The following removes a warning that appears in many of the Atlantic articles.\n",
    "    # Since it is commonly at the beginning, it brings a lot of noise to the search for similar articles\n",
    "    # And subsequently to the assessment of sentiment\n",
    "    targetString=\"For us to continue writing great stories, we need to display ads.             Please select the extension that is blocking ads.     Please follow the steps below\"\n",
    "    df['content']=df['content'].str.replace(targetString,'')\n",
    "\n",
    "    # This is also for some Atlantic articles for the same reasons as above\n",
    "    targetString=\"This article is part of a feature we also send out via email as The Atlantic Daily, a newsletter with stories, ideas, and images from The Atlantic, written specially for subscribers. To sign up, please enter your email address in the field provided here.\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "\n",
    "    # This is also for some Atlantic articles for the same reasons as above\n",
    "    targetString=\"This article is part of a feature we also send out via email as Politics  Policy Daily, a daily roundup of events and ideas in American politics written specially for newsletter subscribers. To sign up, please enter your email address in the field provided here.\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "\n",
    "    # More Atlantic-specific removals (for daily summaries with multiple stories contained)\n",
    "    df=df[df['content'].str.contains(\"To sign up, please enter your email address in the field\")==False]\n",
    "\n",
    "    # Remove daily CNN summary\n",
    "    targetString=\"CNN Student News\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "    \n",
    "    # Remove \"Yahoo ist Teil von Verizon Media\"\n",
    "    targetString = \"Yahoo ist Teil von  Verizon Media\"\n",
    "    df=df[df['content'].str.contains(targetString)==False]\n",
    "    \n",
    "    logging.warning(\"Length after other content filtering: \" + str(df.shape[0]))\n",
    "    \n",
    "    print(\"\\nArticle counts by publisher:\")\n",
    "    print(df['publication'].value_counts())\n",
    "\n",
    "    print(\"\\nArticle counts by date:\")\n",
    "    print(df['date'].value_counts())\n",
    "\n",
    "#     Restrict to articles on the provided input date.\n",
    "#     This date is considered mandatory for topic clustering but is not required for sentiment\n",
    "#     since sentiment only processes a specified list of articles.\n",
    "#     For topic clustering it is essential to have the date as it is\n",
    "#     enormously significant in article matching.\n",
    "\n",
    "    if processDate!=None:\n",
    "        df=df[df['date']==processDate]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Remove non-ASCII characters\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df['content no nonascii']=df['content'].map(lambda x: removeNonASCIICharacters(x))\n",
    "\n",
    "    print(\"\\nFinal dataset:\\n\\nDate:\",processDate,\"\\n\")\n",
    "    print(df['publication'].value_counts())\n",
    "    \n",
    "    print(\"\\nFinal Dataset Article Count:\")\n",
    "    print(df['date'].value_counts())\n",
    "    df.to_csv(r'C:\\Users\\goldm\\Capstone\\tracking files\\getInputDataAndDisplayStats.csv')\n",
    "    \n",
    "    return df\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def removeNonASCIICharacters(textString): \n",
    "    return \"\".join(i for i in textString if ord(i)<128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Length of df before reading: 803\n",
      "WARNING:root:Length of df after >=200 strlen: 773\n",
      "WARNING:root:Length after other content filtering: 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article counts by publisher:\n",
      "Breitbart             104\n",
      "NY Post                61\n",
      "Reuters                59\n",
      "CNN                    58\n",
      "NPR                    54\n",
      "                     ... \n",
      "The Atlantic            1\n",
      "The Times of India      1\n",
      "Forbes                  1\n",
      "PEOPLE.com              1\n",
      "The Economist           1\n",
      "Name: publication, Length: 63, dtype: int64\n",
      "\n",
      "Article counts by date:\n",
      "9/1/2016                                                                                                                                                                      402\n",
      "12/2/2016                                                                                                                                                                     362\n",
      " a tale of child abuse as long and as involved as what Gypsy experienced might have inspired public sympathy. But something about the fraud element deeply offended people      1\n",
      "Name: date, dtype: int64\n",
      "\n",
      "Final dataset:\n",
      "\n",
      "Date: 2016-09-01 \n",
      "\n",
      "Series([], Name: publication, dtype: int64)\n",
      "\n",
      "Final Dataset Article Count:\n",
      "Series([], Name: date, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "articleDataFrame=getInputDataAndDisplayStats(runParams['input_file'][0],\n",
    "                                             runParams['process_date'][0],\n",
    "                                             runParams['article_stats'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Length of df before reading: 803\n",
      "WARNING:root:Length of df after >=200 strlen: 773\n",
      "WARNING:root:Length after other content filtering: 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article counts by publisher:\n",
      "Breitbart             104\n",
      "NY Post                61\n",
      "Reuters                59\n",
      "CNN                    58\n",
      "NPR                    54\n",
      "                     ... \n",
      "The Atlantic            1\n",
      "The Times of India      1\n",
      "Forbes                  1\n",
      "PEOPLE.com              1\n",
      "The Economist           1\n",
      "Name: publication, Length: 63, dtype: int64\n",
      "\n",
      "Article counts by date:\n",
      "9/1/2016                                                                                                                                                                      402\n",
      "12/2/2016                                                                                                                                                                     362\n",
      " a tale of child abuse as long and as involved as what Gypsy experienced might have inspired public sympathy. But something about the fraud element deeply offended people      1\n",
      "Name: date, dtype: int64\n",
      "\n",
      "Final dataset:\n",
      "\n",
      "Date: 2016-09-01 \n",
      "\n",
      "Series([], Name: publication, dtype: int64)\n",
      "\n",
      "Final Dataset Article Count:\n",
      "Series([], Name: date, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>publication</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 354</th>\n",
       "      <th>Unnamed: 355</th>\n",
       "      <th>Unnamed: 356</th>\n",
       "      <th>Unnamed: 357</th>\n",
       "      <th>Unnamed: 358</th>\n",
       "      <th>Unnamed: 359</th>\n",
       "      <th>Unnamed: 360</th>\n",
       "      <th>Unnamed: 361</th>\n",
       "      <th>NYT summary</th>\n",
       "      <th>content no nonascii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 364 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, id, publication, date, content, Unnamed: 5, Unnamed: 6, Unnamed: 7, Unnamed: 8, Unnamed: 9, Unnamed: 10, Unnamed: 11, Unnamed: 12, Unnamed: 13, Unnamed: 14, Unnamed: 15, Unnamed: 16, Unnamed: 17, Unnamed: 18, Unnamed: 19, Unnamed: 20, Unnamed: 21, Unnamed: 22, Unnamed: 23, Unnamed: 24, Unnamed: 25, Unnamed: 26, Unnamed: 27, Unnamed: 28, Unnamed: 29, Unnamed: 30, Unnamed: 31, Unnamed: 32, Unnamed: 33, Unnamed: 34, Unnamed: 35, Unnamed: 36, Unnamed: 37, Unnamed: 38, Unnamed: 39, Unnamed: 40, Unnamed: 41, Unnamed: 42, Unnamed: 43, Unnamed: 44, Unnamed: 45, Unnamed: 46, Unnamed: 47, Unnamed: 48, Unnamed: 49, Unnamed: 50, Unnamed: 51, Unnamed: 52, Unnamed: 53, Unnamed: 54, Unnamed: 55, Unnamed: 56, Unnamed: 57, Unnamed: 58, Unnamed: 59, Unnamed: 60, Unnamed: 61, Unnamed: 62, Unnamed: 63, Unnamed: 64, Unnamed: 65, Unnamed: 66, Unnamed: 67, Unnamed: 68, Unnamed: 69, Unnamed: 70, Unnamed: 71, Unnamed: 72, Unnamed: 73, Unnamed: 74, Unnamed: 75, Unnamed: 76, Unnamed: 77, Unnamed: 78, Unnamed: 79, Unnamed: 80, Unnamed: 81, Unnamed: 82, Unnamed: 83, Unnamed: 84, Unnamed: 85, Unnamed: 86, Unnamed: 87, Unnamed: 88, Unnamed: 89, Unnamed: 90, Unnamed: 91, Unnamed: 92, Unnamed: 93, Unnamed: 94, Unnamed: 95, Unnamed: 96, Unnamed: 97, Unnamed: 98, Unnamed: 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 364 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getInputDataAndDisplayStats(runParams['input_file'][0],\n",
    "                            runParams['process_date'][0],\n",
    "                            printSummary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyzing if any of the articles were \"kicked out\"\n",
    "def listExcludedArticles(articleDataFrame, storyMap):\n",
    "    excluded_list = []\n",
    "    for story, storyArticles in storyMap.items():\n",
    "        for article in storyArticles:\n",
    "            if article in articleDataFrame['id']:\n",
    "                pass\n",
    "            else:\n",
    "                excluded_list.append(article)\n",
    "    return excluded_list\n",
    "#                 print(str(article) + \" was excluded from the dataset\")\n",
    "# print(articleDataFrame.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadStopWords(stopWordsFileName):\n",
    "    stop_words=[]\n",
    "    f=open(stopWordsFileName, 'r')\n",
    "    for l in f.readlines():\n",
    "        stop_words.append(l.replace('\\n', ''))\n",
    "    return stop_words\n",
    "\n",
    "stop_words=loadStopWords(runParams['stop_words_file'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringNLTKProcess(nl,stringToConvert,partsOfSpeech,stop_words,maxWords=None,lemmatizer=None):\n",
    "    sentences=nl.sent_tokenize(stringToConvert)\n",
    "    str=[]\n",
    "    for sentence in sentences:\n",
    "        wordString=[]\n",
    "        for word,pos in nl.pos_tag(nl.word_tokenize(sentence)):\n",
    "            # The following condition avoids any POS which corresponds to punctuation (and takes all others)\n",
    "            if partsOfSpeech==None:\n",
    "                if pos[0]>='A' and pos[0]<='Z':\n",
    "                    wordString.append(word)\n",
    "            elif pos in partsOfSpeech:\n",
    "                wordString.append(word)\n",
    "        for wrd in wordString:\n",
    "            wrdlower=wrd.lower()\n",
    "            if wrdlower not in stop_words and wrdlower!=\"'s\":\n",
    "                if maxWords==None or len(str)<maxWords:\n",
    "                    if lemmatizer==None:\n",
    "                        str.append(wrdlower)\n",
    "                    else:\n",
    "                        str.append(lemmatizer.lemmatize(wrd.lower(), pos='v'))\n",
    "            if maxWords!=None and len(str)==maxWords:\n",
    "                return ' '.join(str)\n",
    "    return ' '.join(str)\n",
    "\n",
    "def removeSpacesAndPunctuation(textString):\n",
    "    return \"\".join(i for i in textString if (ord(i)>=48 and ord(i)<=57) or (ord(i)>=97 and ord(i)<=122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setupStoryMapAndReportList(args=None, reportArticleList=None,storyMapFileName=None):\n",
    "    # Story Map is used in fitting if grid search is applied (As ground truth)\n",
    "    # It is also used in graph if no threshold provided (to determine colours, not to determine location)\n",
    "    # Report Article List is used at the end to create a report with, for each\n",
    "    # article in the list, the set of articles within tolerance, and the key words for each\n",
    "    if args==None:\n",
    "        articleList=reportArticleList\n",
    "        fileName=storyMapFileName\n",
    "    else:\n",
    "        articleList=args['article_id_list']\n",
    "        fileName=args['story_map_validation']\n",
    "    \n",
    "    reportArticleList=articleList\n",
    "    if fileName!=None:\n",
    "        storyMap=readStoryMapFromFile(fileName)\n",
    "        if reportArticleList==None:\n",
    "            reportArticleList=[]\n",
    "            for story, articleList in storyMap.items():\n",
    "                reportArticleList.append(articleList[0])\n",
    "    else:\n",
    "        storyMap=None\n",
    "    return storyMap,reportArticleList\n",
    "\n",
    "def readStoryMapFromFile(filename):\n",
    "    return readDictFromCsvFile(filename,'StoryMap')\n",
    "\n",
    "def readGridParameterRangeFromFile(filename):\n",
    "    return readDictFromCsvFile(filename, 'GridParameters')\n",
    "\n",
    "def readDictFromCsvFile(filename,schema):\n",
    "    gridParamDict={} \n",
    "    with open(filename,'r') as f:\n",
    "        for row in f:\n",
    "            row=row[:-1] # Exclude the carriage return\n",
    "            row=row.split(',')\n",
    "            key=row[0]\n",
    "            vals=row[1:]\n",
    "            \n",
    "            if schema=='GridParameters':\n",
    "                if key in ['story_threshold','tfidf_maxdf']:\n",
    "                    finalVals=list(float(n) for n in vals)\n",
    "                elif key in ['ngram_max','tfidf_mindf','max_length']:\n",
    "                    finalVals=list(int(n) for n in vals)\n",
    "                elif key in ['lemma_conversion','tfidf_binary']:\n",
    "                    finalVals = list(str2bool(n) for n in vals)\n",
    "                elif key in ['parts_of_speech']:\n",
    "                    listlist=[]\n",
    "                    for v in vals:\n",
    "                        listlist.append(v_split('+'))\n",
    "                    finalVals = listlist\n",
    "                elif key in ['tfidf_norm','nlp_library']:\n",
    "                    finalVals=vals\n",
    "                else:\n",
    "                    print(key)\n",
    "                    print(\"KEY ERROR\")\n",
    "                    return\n",
    "            elif schema == 'StoryMap':\n",
    "                finalVals = list(int(n) for n in vals if n!='')\n",
    "            else:\n",
    "                print(schema)\n",
    "                print('SCHEMA ERROR')\n",
    "                return\n",
    "            \n",
    "            gridParamDict[key]=finalVals\n",
    "    return gridParamDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "storyMap,reportArticleList=setupStoryMapAndReportList(storyMapFileName='storyMapForValidation_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump meeting : [151832, 110126, 172078, 48306, 57365, 190512, 26536, 71335, 21499, 23872, 142033, 110133, 23888, 71336, 57366, 71339]\n",
      "Brazil impeachment : [120639, 80103, 25225, 21502, 57362, 120636, 110141]\n",
      "Kaepernick : [40617, 40543, 39520, 80109, 80101, 47403]\n",
      "Clinton Guccifer : [214888, 85803, 47979]\n",
      "Farage : [37252, 37468, 46175]\n",
      "Anthony Weiner : [49480, 110144, 142300, 214934]\n",
      "SpaceX : [38658, 134545, 172095, 214894]\n",
      "Safe space : [21448, 78169, 78171]\n",
      "Lauer debate : [43447, 47078, 138709]\n",
      "Venezuela : [172079, 57375, 190522]\n",
      "Iran deal : [158005, 48823, 57373, 120634]\n",
      "Penn State : [80094, 157527, 214892]\n",
      "David Brown : [172085, 80096, 141886]\n",
      "haiti AND president : [217418, 217419, 217420, 217421, 217422, 217423, 217424, 217425, 217426, 217427, 217428, 217429, 217430, 217431, 217432, 217433, 217434, 217435, 217436, 217437, 217438, 217439, 217440, 217441]\n",
      "inflation AND economy AND fed : [217490, 217491, 217492, 217493, 217494, 217495, 217496, 217497, 217498, 217499, 217500, 217501, 217502, 217504, 217505, 217506, 217507, 217508, 217509, 217510, 217511, 217513, 217514]\n",
      "afghanistan AND war AND end : [217442, 217443, 217444, 217445, 217446, 217447, 217448, 217449, 217450, 217451, 217452, 217453, 217454, 217455, 217456, 217457, 217458, 217459, 217460, 217461, 217462, 217463, 217464, 217465]\n",
      "capitol AND riot AND trump : [217517, 217519, 217520, 217521, 217522, 217523, 217524, 217526, 217527, 217528, 217529, 217530, 217531, 217532, 217533, 217534, 217535, 217536, 217539]\n",
      "critical AND race AND theory : [217466, 217467, 217468, 217469, 217470, 217471, 217472, 217473, 217474, 217475, 217476, 217477, 217478, 217481, 217482, 217483, 217484, 217485, 217486, 217487, 217488, 217489]\n"
     ]
    }
   ],
   "source": [
    "for story, articleList in storyMap.items():\n",
    "    print(story,\":\",articleList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump meeting : [151832, 110126, 172078, 48306, 57365, 190512, 26536, 71335, 21499, 23872, 142033, 110133, 23888, 71336, 57366, 71339]\n",
      "Brazil impeachment : [120639, 80103, 25225, 21502, 57362, 120636, 110141]\n",
      "Kaepernick : [40617, 40543, 39520, 80109, 80101, 47403]\n",
      "Clinton Guccifer : [214888, 85803, 47979]\n",
      "Farage : [37252, 37468, 46175]\n",
      "Anthony Weiner : [49480, 110144, 142300, 214934]\n",
      "SpaceX : [38658, 134545, 172095, 214894]\n",
      "Safe space : [21448, 78169, 78171]\n",
      "Lauer debate : [43447, 47078, 138709]\n",
      "Venezuela : [172079, 57375, 190522]\n",
      "Iran deal : [158005, 48823, 57373, 120634]\n",
      "Penn State : [80094, 157527, 214892]\n",
      "David Brown : [172085, 80096, 141886]\n",
      "haiti AND president : [217418, 217419, 217420, 217421, 217422, 217424, 217425, 217426, 217427, 217428, 217429, 217430, 217431, 217433, 217434, 217435, 217436, 217437, 217438, 217439, 217440, 217441]\n",
      "inflation AND economy AND fed : [217490, 217492, 217493, 217494, 217495, 217496, 217497, 217498, 217500, 217501, 217502, 217504, 217505, 217506, 217507, 217508, 217509, 217510, 217511, 217513, 217514]\n",
      "afghanistan AND war AND end : [217442, 217444, 217446, 217447, 217448, 217450, 217451, 217453, 217454, 217455, 217456, 217457, 217458, 217459, 217460, 217461, 217462, 217464, 217465]\n",
      "capitol AND riot AND trump : [217517, 217519, 217520, 217521, 217522, 217523, 217524, 217526, 217527, 217529, 217530, 217531, 217532, 217533, 217534, 217535, 217536, 217539]\n",
      "critical AND race AND theory : [217466, 217467, 217468, 217469, 217470, 217471, 217472, 217473, 217474, 217475, 217476, 217477, 217478, 217481, 217482, 217483, 217484, 217485, 217486, 217488]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## print out whether any of the labeled articles have been excluded\n",
    "excluded_list = listExcludedArticles(articleDataFrame,storyMap)\n",
    "for story, articleList in storyMap.items():\n",
    "    print(story,\":\",[article for article in articleList if article in list(articleDataFrame['id'])])\n",
    "print(172078 in list(articleDataFrame['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessAndVectorize(articleDataFrame,args,pos_nlp_mapping,nlp,nl,wordnet_lemmatizer,stop_words):\n",
    "    # Map the input parts of speech list to the coding required for the specific NLP library\n",
    "    if args['parts_of_speech'][0]!='ALL':\n",
    "        partsOfSpeech=[]\n",
    "        for pos in args['parts_of_speech']:\n",
    "            partsOfSpeech.append(pos_nlp_mapping[args['nlp_library']][pos])\n",
    "        partsOfSpeech=[item for sublist in partsOfSpeech for item in sublist]\n",
    "    else:\n",
    "        partsOfSpeech=None\n",
    "    \n",
    "    # Processing of text depends on NLP library choice\n",
    "    if args['nlp_library']=='spaCy':\n",
    "        articleDataFrame['input to vectorizer']=articleDataFrame['content no nonascii'].map(lambda x: stringSpaCyProcess(nlp,\n",
    "                                                                                                                         x,\n",
    "                                                                                                                         partsOfSpeech=partsOfSpeech,\n",
    "                                                                                                                         maxWords=args['max_length'],\n",
    "                                                                                                                         stop_words=stop_words,\n",
    "                                                                                                                         lemmatize=args['lemma_conversion']))\n",
    "    elif args['nlp_library']=='nltk':\n",
    "        articleDataFrame['input to vectorizer']=articleDataFrame['content no nonascii'].map(lambda x: stringNLTKProcess(nl,\n",
    "                                                                                                                        x,\n",
    "                                                                                                                        partsOfSpeech=partsOfSpeech,\n",
    "                                                                                                                        stop_words=stop_words,\n",
    "                                                                                                                        maxWords=args['max_length'],\n",
    "                                                                                                                        lemmatizer=wordnet_lemmatizer))\n",
    "    else:\n",
    "        print(\"PROBLEM... NO VALID NLP LIBRARY... MUST BE nltk OR spaCy\")\n",
    "\n",
    "    # To get default values a couple of parameters need to be not passed if not specified on the command line\n",
    "    # Passing as None behaves differently to passing no parameter (which would invoke the default value)\n",
    "    optArgsForVectorizer={}\n",
    "    if args['tfidf_maxdf'] != None:\n",
    "        optArgsForVectorizer['max_df']=args['tfidf_maxdf']\n",
    "    if args['tfidf_mindf'] != None:\n",
    "        optArgsForVectorizer['min_df']=args['tfidf_mindf']\n",
    "    # Create and run the vectorize\n",
    "    vectorizer=TfidfVectorizer(analyzer='word',\n",
    "                               ngram_range=(1,args['ngram_max']),\n",
    "                              lowercase=True,\n",
    "                              binary=args['tfidf_binary'],\n",
    "                              norm=args['tfidf_norm'],\n",
    "                              **optArgsForVectorizer)\n",
    "    tfidfVectors=vectorizer.fit_transform(articleDataFrame['input to vectorizer'])\n",
    "    terms=vectorizer.get_feature_names()\n",
    "    logging.warning('tfidfVector shape: '+ str(tfidfVectors.shape)) \n",
    "    \n",
    "    return tfidfVectors, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,threshold,printErrors=False):\n",
    "    # Work with distances relative to first item in each cluster - even though this is clearly arbitrary since that\n",
    "    # point could be an outlier in the cluster and hence might cause problems.\n",
    "    # But I have to start somewhere - and can refine it later if needed.\n",
    "\n",
    "    nonZeroCoords=initialiseAllNonZeroCoords(tfidfVectors)\n",
    "    score=0\n",
    "    outGood=0\n",
    "    outBad=0\n",
    "    inGood=0\n",
    "    inBad=0\n",
    "     \n",
    "    #### ---- Richard Modification- adding in code to print out a df of articles in the story map and their respective category       \n",
    "    final_mapping_list = []\n",
    "    \n",
    "    for story, storyArticles in storyMap.items():\n",
    "        leadArticleIndex=articleDataFrame[articleDataFrame['id']==storyArticles[0]].index[0]\n",
    "        comparisonArticle = articleDataFrame[articleDataFrame['id']==storyArticles[0]]['id']\n",
    "        # Compute score of all articles in corpus relative to first article in story (.product)\n",
    "        # Then count through list relative to threshold (add one for a good result, subtract one for a bad result)\n",
    "        scores=productRelatednessScores(tfidfVectors,nonZeroCoords,leadArticleIndex)\n",
    "        rankedIndices=np.argsort(scores)\n",
    "        foundRelatedArticles=[]\n",
    "        # THE SORTING HERE IS NOT STRICTLY REQUIRED, BUT I COULD USE IT SO THAT ONCE THE THRESHOLD IS PASSED\n",
    "        # IN THE LOOP, THEN I INFER THE REMAINING RESULTS\n",
    "        for article in reversed(rankedIndices):\n",
    "            thisArticleIndex=articleDataFrame['id'][article]\n",
    "            if thisArticleIndex in storyArticles:\n",
    "                if scores[article]>=threshold: # article IS supposed to be in range\n",
    "                    score+=1\n",
    "                    inGood+=1\n",
    "                    #appending the article and its mapping according to the predictions of our model\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, story, story, 'TP', scores[article]])\n",
    "                else:\n",
    "                    score-=1\n",
    "                    inBad+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, 'No Mapping', story, 'FN', scores[article]])\n",
    "                    if printErrors:\n",
    "                        print(\"ERROR:\",thisArticleIndex,\"should be in\",story)\n",
    "            else: # article not supposed to be in range\n",
    "                if scores[article]<=threshold:\n",
    "                    score+=1\n",
    "                    outGood+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, 'No Mapping', 'No Mapping', 'TN', scores[article]])\n",
    "                else:\n",
    "                    score-=1\n",
    "                    outBad+=1\n",
    "                    final_mapping_list.append([comparisonArticle, thisArticleIndex, story, 'No Mapping', 'FP', scores[article]])\n",
    "                    if printErrors:\n",
    "                        print(\"ERROR:\",thisArticleIndex,\"should NOT be in\",story)\n",
    "    \n",
    "    #### ---- Richard Modification- adding in code to print out a df of articles in the story map and their respective categor\n",
    "    final_mapping_df = pd.DataFrame(final_mapping_list, columns = ['root_article', 'article_compared', 'predicted_mapping', 'true_mapping\"','FP/FN/TP/TN', \"score\"])\n",
    "    final_mapping_df = final_mapping_df[final_mapping_df.score != 0]\n",
    "    final_mapping_df.to_csv(\"PredictedMappingsv4-storythreshold={}.csv\".format(threshold))\n",
    "    \n",
    "    scoreDict={'score':score,'inGood':inGood,'inBad':inBad,'outGood':outGood,'outBad':outBad}\n",
    "    return scoreDict\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "def initialiseAllNonZeroCoords(tfidfVectors):\n",
    "# This function just exists since it seems to be expensive and I'd rather not call it multiple times\n",
    "# Hence it is intended to be called outside of loops in order to simplify the row specific processing\n",
    "    values=[]\n",
    "    nzc=zip(*tfidfVectors.nonzero())\n",
    "\n",
    "    # In Python 3 the zip can only be iterated through one time before it is automatically released\n",
    "    # So need to copy the results otherwise the main loop below will no longer work\n",
    "    pointList=[]\n",
    "    for i,j in nzc:\n",
    "        pointList.append([i,j])\t\t\n",
    "\n",
    "    for row in range(tfidfVectors.shape[0]):\n",
    "        rowList=[]\n",
    "        for i,j in pointList:\n",
    "            if row==i:\n",
    "                rowList.append(j)\n",
    "        values.append(rowList)\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productRelatednessScores(tfidfVectors,nonZeroCoords,refRow):\n",
    "    # instantiates a matrix of zeros with tfidVectors.shape[0] rows corresponding to the number of rows in the tfidVectors array\n",
    "    scores = [0]*tfidfVectors.shape[0]\n",
    "    for toRow in range(tfidfVectors.shape[0]):\n",
    "        scores[toRow] = sum([(tfidfVectors[toRow,w]*tfidfVectors[refRow,w]) for w in nonZeroCoords[refRow] if w in nonZeroCoords[toRow]])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\goldm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk; nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tfidfVector shape: (402, 4182)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 7064, 'inGood': 80, 'inBad': 82, 'outGood': 7070, 'outBad': 4}\n"
     ]
    }
   ],
   "source": [
    "# Loop across all parameter combinations in grid to determine best set\n",
    "# If not doing grid search, will just pass through the loop once\n",
    "bestParamScoreDict={'score':-1000000}\n",
    "bestParams=parameterGrid[0]\n",
    "for i,currentParams in enumerate(parameterGrid):\n",
    "    if len(parameterGrid)>1:\n",
    "        print(\"Combination:\",i+1,\"of\",len(parameterGrid))\n",
    "        print(currentParams)\n",
    "        \n",
    "        # Determine tf-idf vectors\n",
    "        # terms is just used later on if analysis of final results is requested\n",
    "    tfidfVectors,terms=preprocessAndVectorize(articleDataFrame,\n",
    "                                              currentParams,\n",
    "                                              pos_nlp_mapping,\n",
    "                                              nlp,\n",
    "                                              nl,\n",
    "                                              wordnet_lemmatizer,\n",
    "                                              stop_words)\n",
    "\n",
    "    # Compute scores if threshold provided (meaning as part of grid search)\n",
    "    if 'story_threshold' in currentParams and currentParams['story_threshold']!=None:\n",
    "        scoreDict = scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,currentParams['story_threshold'])\n",
    "        print(scoreDict)\n",
    "\n",
    "        # Update best so far\n",
    "        if scoreDict['score']>=bestParamScoreDict['score']:\n",
    "            if len(parameterGrid)>1:\n",
    "                print(i+1,\"is the best so far!\")\n",
    "            bestParams=currentParams\n",
    "            bestParamScoreDict=scoreDict\n",
    "    # End grid/parameter loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMETERS:\n",
      "{'article_stats': False, 'display_graph': True, 'input_file': './data/articles_combined_formattedv1.csv', 'lemma_conversion': False, 'max_length': 50, 'ngram_max': 3, 'nlp_library': 'nltk', 'parts_of_speech': ['PROPER', 'VERB'], 'process_date': '2016-09-01', 'stop_words_file': './data/stopWords.txt', 'story_threshold': 0.2, 'tfidf_binary': False, 'tfidf_maxdf': 0.5, 'tfidf_mindf': 2, 'tfidf_norm': 'l2'}\n",
      "{'score': 7356, 'inGood': 86, 'inBad': 95, 'outGood': 7381, 'outBad': 16}\n",
      "ERROR: 214876 should NOT be in Trump meeting\n",
      "ERROR: 80098 should NOT be in Trump meeting\n",
      "ERROR: 78170 should NOT be in Trump meeting\n",
      "ERROR: 44928 should NOT be in Trump meeting\n",
      "ERROR: 71339 should be in Trump meeting\n",
      "ERROR: 85801 should NOT be in Clinton Guccifer\n",
      "ERROR: 44642 should NOT be in Safe space\n",
      "ERROR: 85799 should NOT be in Lauer debate\n",
      "ERROR: 39232 should NOT be in David Brown\n",
      "ERROR: 71350 should NOT be in David Brown\n",
      "ERROR: 217425 should be in haiti AND president\n",
      "ERROR: 217437 should be in haiti AND president\n",
      "ERROR: 217429 should be in haiti AND president\n",
      "ERROR: 217426 should be in haiti AND president\n",
      "ERROR: 217439 should be in haiti AND president\n",
      "ERROR: 217433 should be in haiti AND president\n",
      "ERROR: 217422 should be in haiti AND president\n",
      "ERROR: 217419 should be in haiti AND president\n",
      "ERROR: 217421 should be in haiti AND president\n",
      "ERROR: 217432 should be in haiti AND president\n",
      "ERROR: 217438 should be in haiti AND president\n",
      "ERROR: 217428 should be in haiti AND president\n",
      "ERROR: 217420 should be in haiti AND president\n",
      "ERROR: 217435 should be in haiti AND president\n",
      "ERROR: 217431 should be in haiti AND president\n",
      "ERROR: 217427 should be in haiti AND president\n",
      "ERROR: 217418 should be in haiti AND president\n",
      "ERROR: 217424 should be in haiti AND president\n",
      "ERROR: 217430 should be in haiti AND president\n",
      "ERROR: 217500 should be in inflation AND economy AND fed\n",
      "ERROR: 217497 should be in inflation AND economy AND fed\n",
      "ERROR: 217504 should be in inflation AND economy AND fed\n",
      "ERROR: 217495 should be in inflation AND economy AND fed\n",
      "ERROR: 217501 should be in inflation AND economy AND fed\n",
      "ERROR: 217503 should be in inflation AND economy AND fed\n",
      "ERROR: 217496 should be in inflation AND economy AND fed\n",
      "ERROR: 217509 should be in inflation AND economy AND fed\n",
      "ERROR: 217506 should be in inflation AND economy AND fed\n",
      "ERROR: 217513 should be in inflation AND economy AND fed\n",
      "ERROR: 217512 should be in inflation AND economy AND fed\n",
      "ERROR: 217505 should be in inflation AND economy AND fed\n",
      "ERROR: 217499 should be in inflation AND economy AND fed\n",
      "ERROR: 217494 should be in inflation AND economy AND fed\n",
      "ERROR: 217502 should be in inflation AND economy AND fed\n",
      "ERROR: 217508 should be in inflation AND economy AND fed\n",
      "ERROR: 217511 should be in inflation AND economy AND fed\n",
      "ERROR: 217445 should be in afghanistan AND war AND end\n",
      "ERROR: 217456 should be in afghanistan AND war AND end\n",
      "ERROR: 217452 should be in afghanistan AND war AND end\n",
      "ERROR: 217453 should be in afghanistan AND war AND end\n",
      "ERROR: 217464 should be in afghanistan AND war AND end\n",
      "ERROR: 217459 should be in afghanistan AND war AND end\n",
      "ERROR: 217455 should be in afghanistan AND war AND end\n",
      "ERROR: 217447 should be in afghanistan AND war AND end\n",
      "ERROR: 217448 should be in afghanistan AND war AND end\n",
      "ERROR: 217450 should be in afghanistan AND war AND end\n",
      "ERROR: 217458 should be in afghanistan AND war AND end\n",
      "ERROR: 217460 should be in afghanistan AND war AND end\n",
      "ERROR: 217457 should be in afghanistan AND war AND end\n",
      "ERROR: 217443 should be in afghanistan AND war AND end\n",
      "ERROR: 217444 should be in afghanistan AND war AND end\n",
      "ERROR: 217446 should be in afghanistan AND war AND end\n",
      "ERROR: 217454 should be in afghanistan AND war AND end\n",
      "ERROR: 217461 should be in afghanistan AND war AND end\n",
      "ERROR: 217462 should be in afghanistan AND war AND end\n",
      "ERROR: 217451 should be in afghanistan AND war AND end\n",
      "ERROR: 217449 should be in afghanistan AND war AND end\n",
      "ERROR: 217463 should be in afghanistan AND war AND end\n",
      "ERROR: 217502 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217511 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217479 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217478 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217508 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217488 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217485 should NOT be in capitol AND riot AND trump\n",
      "ERROR: 217538 should be in capitol AND riot AND trump\n",
      "ERROR: 217516 should be in capitol AND riot AND trump\n",
      "ERROR: 217518 should be in capitol AND riot AND trump\n",
      "ERROR: 217519 should be in capitol AND riot AND trump\n",
      "ERROR: 217520 should be in capitol AND riot AND trump\n",
      "ERROR: 217521 should be in capitol AND riot AND trump\n",
      "ERROR: 217522 should be in capitol AND riot AND trump\n",
      "ERROR: 217523 should be in capitol AND riot AND trump\n",
      "ERROR: 217525 should be in capitol AND riot AND trump\n",
      "ERROR: 217526 should be in capitol AND riot AND trump\n",
      "ERROR: 217528 should be in capitol AND riot AND trump\n",
      "ERROR: 217529 should be in capitol AND riot AND trump\n",
      "ERROR: 217530 should be in capitol AND riot AND trump\n",
      "ERROR: 217531 should be in capitol AND riot AND trump\n",
      "ERROR: 217532 should be in capitol AND riot AND trump\n",
      "ERROR: 217533 should be in capitol AND riot AND trump\n",
      "ERROR: 217534 should be in capitol AND riot AND trump\n",
      "ERROR: 217535 should be in capitol AND riot AND trump\n",
      "ERROR: 217475 should be in critical AND race AND theory\n",
      "ERROR: 217477 should be in critical AND race AND theory\n",
      "ERROR: 217470 should be in critical AND race AND theory\n",
      "ERROR: 217473 should be in critical AND race AND theory\n",
      "ERROR: 217468 should be in critical AND race AND theory\n",
      "ERROR: 217467 should be in critical AND race AND theory\n",
      "ERROR: 217480 should be in critical AND race AND theory\n",
      "ERROR: 217487 should be in critical AND race AND theory\n",
      "ERROR: 217481 should be in critical AND race AND theory\n",
      "ERROR: 217471 should be in critical AND race AND theory\n",
      "ERROR: 217484 should be in critical AND race AND theory\n",
      "ERROR: 217486 should be in critical AND race AND theory\n",
      "ERROR: 217474 should be in critical AND race AND theory\n",
      "ERROR: 217476 should be in critical AND race AND theory\n",
      "ERROR: 217478 should be in critical AND race AND theory\n",
      "ERROR: 217479 should be in critical AND race AND theory\n",
      "ERROR: 217485 should be in critical AND race AND theory\n",
      "ERROR: 217488 should be in critical AND race AND theory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tfidfVector shape: (421, 4727)\n"
     ]
    }
   ],
   "source": [
    "# Set threshold to input value from best (and possibly only) run for use in results analysis\n",
    "# Unless not specified at all\n",
    "if 'story_threshold' in bestParams and bestParams['story_threshold']!=None:\n",
    "    threshold=bestParams['story_threshold']\n",
    "else:\n",
    "    threshold=None\n",
    "\n",
    "\n",
    "# If there was a real parameter grid, then output/refresh results\n",
    "if len(parameterGrid)>=1:\n",
    "    print(\"BEST PARAMETERS:\")\n",
    "    print(bestParams)\n",
    "    print(bestParamScoreDict)\n",
    "    scoreCurrentParamGuess(tfidfVectors,storyMap,articleDataFrame,threshold,printErrors=True)\n",
    "    # Recreate vector for best results in loop\n",
    "    # terms is just used later on if analysis of final results is requested\n",
    "    tfidfVectors,terms=preprocessAndVectorize(articleDataFrame,\n",
    "                                            bestParams,\n",
    "                                            pos_nlp_mapping,\n",
    "                                            nlp,\n",
    "                                            nl,\n",
    "                                            wordnet_lemmatizer,\n",
    "                                            stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets generate a confusion matrix to evaluate our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels= pd.read_csv(r\"C:\\Users\\goldm\\Capstone\\full_article_classifications_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>true-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48306</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57365</td>\n",
       "      <td>Trump meeting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id     true-label\n",
       "0  151832  Trump meeting\n",
       "1  110126  Trump meeting\n",
       "2  172078  Trump meeting\n",
       "3   48306  Trump meeting\n",
       "4   57365  Trump meeting"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.columns = ['id','true-label']\n",
    "true_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mappings_df = pd.read_csv(r\"C:\\Users\\goldm\\Capstone\\PredictedMappingsv4-storythreshold=0.26.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>root_article</th>\n",
       "      <th>article_compared</th>\n",
       "      <th>predicted_mapping</th>\n",
       "      <th>true_mapping\"</th>\n",
       "      <th>FP/FN/TP/TN</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>151832</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>48306</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.421409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>172078</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.400392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>110126</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.374014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>227    151832\\nName: id, dtype: int64</td>\n",
       "      <td>26536</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>Trump meeting</td>\n",
       "      <td>TP</td>\n",
       "      <td>0.346913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           root_article  article_compared  \\\n",
       "0           0  227    151832\\nName: id, dtype: int64            151832   \n",
       "1           1  227    151832\\nName: id, dtype: int64             48306   \n",
       "2           2  227    151832\\nName: id, dtype: int64            172078   \n",
       "3           3  227    151832\\nName: id, dtype: int64            110126   \n",
       "4           4  227    151832\\nName: id, dtype: int64             26536   \n",
       "\n",
       "  predicted_mapping  true_mapping\" FP/FN/TP/TN     score  \n",
       "0     Trump meeting  Trump meeting          TP  1.000000  \n",
       "1     Trump meeting  Trump meeting          TP  0.421409  \n",
       "2     Trump meeting  Trump meeting          TP  0.400392  \n",
       "3     Trump meeting  Trump meeting          TP  0.374014  \n",
       "4     Trump meeting  Trump meeting          TP  0.346913  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Trump meeting', 'No Mapping', 'Brazil impeachment', 'Kaepernick',\n",
       "       'Clinton Guccifer', 'Farage', 'Anthony Weiner', 'SpaceX',\n",
       "       'Safe space', 'Lauer debate', 'Venezuela', 'Iran deal',\n",
       "       'Penn State', 'David Brown', 'haiti AND president',\n",
       "       'inflation AND economy AND fed', 'afghanistan AND war AND end',\n",
       "       'capitol AND riot AND trump', 'critical AND race AND theory'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df['predicted_mapping'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = predicted_mappings_df[['predicted_mapping', 'true_mapping\"']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.979, precision = 0.979, recall = 0.979, f1 = 0.979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "y_test = label_set['true_mapping\"']\n",
    "y_pred = label_set['predicted_mapping']\n",
    "\n",
    "def get_metrics(y_test, y_predicted):  \n",
    "    # true positives / (true positives+false positives)\n",
    "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
    "                                    average='micro')             \n",
    "    # true positives / (true positives + false negatives)\n",
    "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
    "                              average='micro')\n",
    "    \n",
    "    # harmonic mean of precision and recall\n",
    "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='micro')\n",
    "    \n",
    "    # true positives + true negatives/ total\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TN    3760\n",
       "TP      80\n",
       "FN      78\n",
       "FP       4\n",
       "Name: FP/FN/TP/TN, dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_mappings_df['FP/FN/TP/TN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
